{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "os.chdir('../')\n",
    "CODE_DIR = 'DualStyleGAN'\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/williamyang1991/DualStyleGAN.git $CODE_DIR\n",
    "!wget https://github.com/ninja-build/ninja/releases/download/v1.8.2/ninja-linux.zip\n",
    "!sudo unzip ninja-linux.zip -d /usr/local/bin/\n",
    "!sudo update-alternatives --install /usr/bin/ninja ninja /usr/local/bin/ninja 1 --force \n",
    "!pip install faiss-cpu\n",
    "!pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(f'./{CODE_DIR}')\n",
    "MODEL_DIR = os.path.join(os.path.dirname(os.getcwd()), CODE_DIR, 'checkpoint')\n",
    "DATA_DIR = os.path.join(os.path.dirname(os.getcwd()), CODE_DIR, 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append(\".\")\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from util import save_image, load_image, visualize\n",
    "import argparse\n",
    "from argparse import Namespace\n",
    "from torchvision import transforms\n",
    "from torch.nn import functional as F\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from model.dualstylegan import DualStyleGAN\n",
    "from model.sampler.icp import ICPTrainer\n",
    "from model.encoder.psp import pSp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_types = ['cartoon', 'caricature', 'anime', 'arcane', 'comic', 'pixar', 'slamdunk']\n",
    "style_type = style_types[0]\n",
    "\n",
    "if not os.path.exists(os.path.join(MODEL_DIR, style_type)):\n",
    "    os.makedirs(os.path.join(MODEL_DIR, style_type))\n",
    "\n",
    "def get_download_model_command(file_id, file_name):\n",
    "    \"\"\" Get wget download command for downloading the desired model and save to directory ../checkpoint/. \"\"\"\n",
    "    current_directory = os.getcwd()\n",
    "    save_path = MODEL_DIR\n",
    "    url = r\"\"\"wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id={FILE_ID}' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id={FILE_ID}\" -O {SAVE_PATH}/{FILE_NAME} && rm -rf /tmp/cookies.txt\"\"\".format(FILE_ID=file_id, FILE_NAME=file_name, SAVE_PATH=save_path)\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATHS = {\n",
    "    \"encoder\": {\"id\": \"1NgI4mPkboYvYw3MWcdUaQhkr0OWgs9ej\", \"name\": \"encoder.pt\"},\n",
    "    \"cartoon-G\": {\"id\": \"1exS9cSFkg8J4keKPmq2zYQYfJYC5FkwL\", \"name\": \"generator.pt\"},\n",
    "    \"cartoon-N\": {\"id\": \"1JSCdO0hx8Z5mi5Q5hI9HMFhLQKykFX5N\", \"name\": \"sampler.pt\"},\n",
    "    \"cartoon-S\": {\"id\": \"1ce9v69JyW_Dtf7NhbOkfpH77bS_RK0vB\", \"name\": \"refined_exstyle_code.npy\"},\n",
    "    \"caricature-G\": {\"id\": \"1BXfTiMlvow7LR7w8w0cNfqIl-q2z0Hgc\", \"name\": \"generator.pt\"},\n",
    "    \"caricature-N\": {\"id\": \"1eJSoaGD7X0VbHS47YLehZayhWDSZ4L2Q\", \"name\": \"sampler.pt\"},\n",
    "    \"caricature-S\": {\"id\": \"1-p1FMRzP_msqkjndRK_0JasTdwQKDsov\", \"name\": \"refined_exstyle_code.npy\"},\n",
    "    \"anime-G\": {\"id\": \"1BToWH-9kEZIx2r5yFkbjoMw0642usI6y\", \"name\": \"generator.pt\"},\n",
    "    \"anime-N\": {\"id\": \"19rLqx_s_SUdiROGnF_C6_uOiINiNZ7g2\", \"name\": \"sampler.pt\"},\n",
    "    \"anime-S\": {\"id\": \"17-f7KtrgaQcnZysAftPogeBwz5nOWYuM\", \"name\": \"refined_exstyle_code.npy\"},\n",
    "    \"arcane-G\": {\"id\": \"15l2O7NOUAKXikZ96XpD-4khtbRtEAg-Q\", \"name\": \"generator.pt\"},\n",
    "    \"arcane-N\": {\"id\": \"1fa7p9ZtzV8wcasPqCYWMVFpb4BatwQHg\", \"name\": \"sampler.pt\"},\n",
    "    \"arcane-S\": {\"id\": \"1z3Nfbir5rN4CrzatfcgQ8u-x4V44QCn1\", \"name\": \"exstyle_code.npy\"},\n",
    "    \"comic-G\": {\"id\": \"1_t8lf9lTJLnLXrzhm7kPTSuNDdiZnyqE\", \"name\": \"generator.pt\"},\n",
    "    \"comic-N\": {\"id\": \"1RXrJPodIn7lCzdb5BFc03kKqHEazaJ-S\", \"name\": \"sampler.pt\"},\n",
    "    \"comic-S\": {\"id\": \"1ZfQ5quFqijvK3hO6f-YDYJMqd-UuQtU-\", \"name\": \"exstyle_code.npy\"},\n",
    "    \"pixar-G\": {\"id\": \"1TgH7WojxiJXQfnCroSRYc7BgxvYH9i81\", \"name\": \"generator.pt\"},\n",
    "    \"pixar-N\": {\"id\": \"18e5AoQ8js4iuck7VgI3hM_caCX5lXlH_\", \"name\": \"sampler.pt\"},\n",
    "    \"pixar-S\": {\"id\": \"1I9mRTX2QnadSDDJIYM_ntyLrXjZoN7L-\", \"name\": \"exstyle_code.npy\"},    \n",
    "    \"slamdunk-G\": {\"id\": \"1MGGxSCtyf9399squ3l8bl0hXkf5YWYNz\", \"name\": \"generator.pt\"},\n",
    "    \"slamdunk-N\": {\"id\": \"1-_L7YVb48sLr_kPpOcn4dUq7Cv08WQuG\", \"name\": \"sampler.pt\"},\n",
    "    \"slamdunk-S\": {\"id\": \"1Dgh11ZeXS2XIV2eJZAExWMjogxi_m_C8\", \"name\": \"exstyle_code.npy\"},     \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download pSp encoder\n",
    "path = MODEL_PATHS[\"encoder\"]\n",
    "download_command = get_download_model_command(file_id=path[\"id\"], file_name=path[\"name\"])\n",
    "!{download_command}\n",
    "# download dualstylegan\n",
    "path = MODEL_PATHS[style_type+'-G']\n",
    "download_command = get_download_model_command(file_id=path[\"id\"], file_name=os.path.join(style_type, path[\"name\"]))\n",
    "!{download_command}\n",
    "# download sampler\n",
    "path = MODEL_PATHS[style_type+'-N']\n",
    "download_command = get_download_model_command(file_id=path[\"id\"], file_name=os.path.join(style_type, path[\"name\"]))\n",
    "!{download_command}\n",
    "# download extrinsic style code\n",
    "path = MODEL_PATHS[style_type+'-S']\n",
    "download_command = get_download_model_command(file_id=path[\"id\"], file_name=os.path.join(style_type, path[\"name\"]))\n",
    "!{download_command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(256),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# load DualStyleGAN\n",
    "generator = DualStyleGAN(1024, 512, 8, 2, res_index=6)\n",
    "generator.eval()\n",
    "ckpt = torch.load(os.path.join(MODEL_DIR, style_type, 'generator.pt'), map_location=lambda storage, loc: storage)\n",
    "generator.load_state_dict(ckpt[\"g_ema\"])\n",
    "generator = generator.to(device)\n",
    "\n",
    "# load encoder\n",
    "model_path = os.path.join(MODEL_DIR, 'encoder.pt')\n",
    "ckpt = torch.load(model_path, map_location='cpu')\n",
    "opts = ckpt['opts']\n",
    "opts['checkpoint_path'] = model_path\n",
    "opts = Namespace(**opts)\n",
    "opts.device = device\n",
    "encoder = pSp(opts)\n",
    "encoder.eval()\n",
    "encoder = encoder.to(device)\n",
    "\n",
    "# load extrinsic style code\n",
    "exstyles = np.load(os.path.join(MODEL_DIR, style_type, MODEL_PATHS[style_type+'-S'][\"name\"]), allow_pickle='TRUE').item()\n",
    "\n",
    "# load sampler network\n",
    "icptc = ICPTrainer(np.empty([0,512*11]), 128)\n",
    "icpts = ICPTrainer(np.empty([0,512*7]), 128)\n",
    "ckpt = torch.load(os.path.join(MODEL_DIR, style_type, 'sampler.pt'), map_location=lambda storage, loc: storage)\n",
    "icptc.icp.netT.load_state_dict(ckpt['color'])\n",
    "icpts.icp.netT.load_state_dict(ckpt['structure'])\n",
    "icptc.icp.netT = icptc.icp.netT.to(device)\n",
    "icpts.icp.netT = icpts.icp.netT.to(device)\n",
    "\n",
    "print('Model successfully loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import torch\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "#!pip install removebg\n",
    "#!pip3 install remove-bg-api\n",
    "#from remove_bg_api import RemoveBg as rmbg\n",
    "#api_key = \"p7kt2SCdEMSUXFHAmyeDyrX1\"\n",
    "#rmbg = rmbg(api_key)\n",
    "#-----------------------------------\n",
    "#!pip install imageio==2.4.1\n",
    "#!pip install imageio-ffmpeg\n",
    "#!pip install imageio-moviepy\n",
    "#import os\n",
    "#os.chdir('/content')  # 使用 Colab 要換路徑使用\n",
    "#from moviepy.editor import *\n",
    "#from moviepy.video.fx.all import *\n",
    "#video = VideoFileClip('/content/test1.mp4')     # 讀取影片\n",
    "#output_1 = speedx(video, factor=2)          # 2 倍速\n",
    "#output_2 = speedx(video, factor=0.1)        # 0.1 倍速\n",
    "#output_3 = speedx(video, final_duration=2)  # 將影片變成 2 秒長\n",
    "\n",
    "#output_1.write_videofile(\"output_1.mp4\",temp_audiofile=\"temp-audio.m4a\", remove_temp=True, codec=\"libx264\", audio_codec=\"aac\")\n",
    "#output_2.write_videofile('/content/test2.mp4',temp_audiofile=\"temp-audio.m4a\", remove_temp=True, codec=\"libx264\", audio_codec=\"aac\")\n",
    "#output_3.write_videofile(\"output_3.mp4\",temp_audiofile=\"temp-audio.m4a\", remove_temp=True, codec=\"libx264\", audio_codec=\"aac\")\n",
    "\n",
    "#print('ok')\n",
    "#-----------------------------------\n",
    "vidcap = cv2.VideoCapture('/content/test1.mp4')\n",
    "success,image = vidcap.read()\n",
    "count = 0\n",
    "#-----------------------------------\n",
    "loader = transforms.Compose([transforms.ToTensor(),transforms.Resize(256),\n",
    "        transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])  \n",
    "unloader = transforms.ToPILImage()\n",
    "#-----------------------------------\n",
    "while success:\n",
    "  cv2.imwrite(\"new_image%d.jpg\"% count, image)     # save frame as JPEG file   \n",
    "  success,image = vidcap.read()\n",
    "  print(\"new_image%d.jpg\"% count)\n",
    "  #rmbg.remove_bg_file(input_path='image0.jpg', out_path='new_image0.jpg')\n",
    "  #mgplot = plt.imshow(img)\n",
    "  #plt.show()\n",
    "  image_path = 'new_image%d.jpg'% count\n",
    "  original_image = load_image(image_path)\n",
    "  #-------------------------------------\n",
    "  plt.figure(figsize=(10,10),dpi=30)\n",
    "  visualize(original_image[0])\n",
    "  plt.show()\n",
    "  #-------------------------------------\n",
    "  if_align_face = True\n",
    "  def run_alignment(image_path):\n",
    "    import dlib\n",
    "    from model.encoder.align_all_parallel import align_face\n",
    "    modelname = os.path.join(MODEL_DIR, 'shape_predictor_68_face_landmarks.dat')\n",
    "    if not os.path.exists(modelname):\n",
    "        import wget, bz2\n",
    "        wget.download('http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2', modelname+'.bz2')\n",
    "        zipfile = bz2.BZ2File(modelname+'.bz2')\n",
    "        data = zipfile.read()\n",
    "        open(modelname, 'wb').write(data)\n",
    "    predictor = dlib.shape_predictor(modelname)\n",
    "    aligned_image = align_face(filepath=image_path, predictor=predictor)\n",
    "    return aligned_image\n",
    "  #------------------------------------\n",
    "  if if_align_face:\n",
    "    I = transform(run_alignment(image_path)).unsqueeze(dim=0).to(device)\n",
    "  else:\n",
    "    I = F.adaptive_avg_pool2d(load_image(image_path).to(device), 256)\n",
    "  #------------------------------------\n",
    "  plt.figure(figsize=(10,10),dpi=30)\n",
    "  visualize(I[0].cpu()) #I是切好的image\n",
    "  plt.show()\n",
    "  #------------------------------------\n",
    "  style_id = 53\n",
    "  stylename = list(exstyles.keys())[style_id]\n",
    "  stylepath = os.path.join(DATA_DIR, style_type, 'images/train', stylename)\n",
    "  #stylename = \"user_style_0.jpg\"\n",
    "  #stylepath = \"/DualStyleGAN/data/cartoon/images/train/user_style_0.jpg\"\n",
    "  print('loading %s'%stylepath)\n",
    "  if os.path.exists(stylepath):\n",
    "    S = load_image(stylepath) \n",
    "    plt.figure(figsize=(10,10),dpi=30)\n",
    "    visualize(S[0]) #S是style_image\n",
    "    plt.show()\n",
    "  else:\n",
    "    print('%s is not found'%stylename)\n",
    "  #-----------------------------\n",
    "  with torch.no_grad():\n",
    "    img_rec, instyle = encoder(I, randomize_noise=False, return_latents=True, \n",
    "                            z_plus_latent=True, return_z_plus_latent=True, resize=False)    \n",
    "    img_rec = torch.clamp(img_rec.detach(), -1, 1)\n",
    "    \n",
    "    latent = torch.tensor(exstyles[stylename]).repeat(2,1,1).to(device)\n",
    "    # latent[0] for both color and structrue transfer and latent[1] for only structrue transfer\n",
    "    latent[1,7:18] = instyle[0,7:18]\n",
    "    exstyle = generator.generator.style(latent.reshape(latent.shape[0]*latent.shape[1], latent.shape[2])).reshape(latent.shape)\n",
    "    \n",
    "    img_gen, _ = generator([instyle.repeat(2,1,1)], exstyle, z_plus_latent=True, \n",
    "                           truncation=0.7, truncation_latent=0, use_res=True, interp_weights=[0.6]*7+[0]*11)\n",
    "    img_gen = torch.clamp(img_gen.detach(), -1, 1)\n",
    "    # deactivate color-related layers by setting w_c = 0\n",
    "    img_gen2, _ = generator([instyle], exstyle[0:1], z_plus_latent=True, \n",
    "                            truncation=0.7, truncation_latent=0, use_res=True, interp_weights=[0.6]*7+[0]*11)\n",
    "    img_gen2 = torch.clamp(img_gen2.detach(), -1, 1)\n",
    "  #------------------------------\n",
    "  #vis = torchvision.utils.make_grid(F.adaptive_avg_pool2d(torch.cat([img_rec, img_gen, img_gen2], dim=0), 256), 4, 1)\n",
    "  plt.figure(figsize=(5,5),dpi=120)\n",
    "  fig = plt.gcf()\n",
    "  #plt.show()\n",
    "  #print(vis)\n",
    "  visualize(img_gen[0].cpu())\n",
    "  plt.savefig(\"transfer_image_A%d.jpg\"% count, bbox_inches='tight')\n",
    "  visualize(img_gen[1].cpu())\n",
    "  plt.savefig(\"transfer_image_B%d.jpg\"% count, bbox_inches='tight')\n",
    "  #visualize(img_gen2.cpu())\n",
    "  #plt.savefig(\"transfer_image_C%d.jpg\"% count, bbox_inches='tight')\n",
    "  #------------------------------\n",
    "  #def plti(im, **kwargs):\n",
    "    #\"\"\"\n",
    "    #画图的辅助函数\n",
    "    #\"\"\"\n",
    "    #plt.imshow(im, interpolation=\"none\", **kwargs)\n",
    "    #plt.axis('off') # 去掉坐标轴\n",
    "  \n",
    "  #im = plt.imread(\"transfer_image%d.jpg\"% count)\n",
    "  #im = im[0:360,0:240] # 直接切片对图像进行裁剪\n",
    "  #plti(im)\n",
    "  #plt.savefig(\"transfer_image_A%d.jpg\"% count, bbox_inches='tight')\n",
    "  #im = plt.imread(\"transfer_image%d.jpg\"% count)\n",
    "  #im = im[0:360,250:470] # 直接切片对图像进行裁剪\n",
    "  #plti(im)\n",
    "  #plt.savefig(\"transfer_image_B%d.jpg\"% count, bbox_inches='tight')\n",
    "  #im = plt.imread(\"transfer_image%d.jpg\"% count)\n",
    "  #im = im[0:360,480:710] # 直接切片对图像进行裁剪\n",
    "  #plti(im)\n",
    "  #plt.savefig(\"transfer_image_C%d.jpg\"% count, bbox_inches='tight')\n",
    "  #im = plt.imread(\"transfer_image%d.jpg\"% count)\n",
    "  #im = im[0:360,720:960] # 直接切片对图像进行裁剪\n",
    "  #plti(im)\n",
    "  #plt.savefig(\"transfer_image_D%d.jpg\"% count, bbox_inches='tight')\n",
    "  #------------------------------\n",
    "  #img = PIL.Image.fromarray(torch.clamp(vis * 255, min=0, max=255).byte().permute(1, 2, 0).cpu().numpy())\n",
    "  #img = torchvision.transforms.functional.to_pil_image(vis)\n",
    "  #img.save(\"transfer_image%d.jpg\"% count)\n",
    "  #-----------------------------\n",
    "  #def tensor_to_PIL(tensor):\n",
    "    #image = tensor.cpu().clone()\n",
    "    #image = image.squeeze(0)\n",
    "    #image = unloader(image)\n",
    "    #return image\n",
    "  #transfer_image = tensor_to_PIL(vis)\n",
    "  #transfer_image.save(\"transfer_image%d.jpg\"% count)\n",
    "  #---------------------------------\n",
    "  count += 1\n",
    "  #---------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "video = cv2.VideoWriter('/content/output_A.avi', cv2.VideoWriter_fourcc(*'MJPG'), 10, (320, 320))\n",
    "for i in range(0,30):\n",
    "  img = cv2.imread(\"transfer_image_A%d.jpg\"% i)\n",
    "  img = cv2.resize(img, (320, 320))\n",
    "  video.write(img)\n",
    "video.release()\n",
    "\n",
    "video = cv2.VideoWriter('/content/output_B.avi', cv2.VideoWriter_fourcc(*'MJPG'), 10, (320, 320))\n",
    "for i in range(0,30):\n",
    "  img = cv2.imread(\"transfer_image_B%d.jpg\"% i)\n",
    "  img = cv2.resize(img, (320, 320))\n",
    "  video.write(img)\n",
    "video.release()\n",
    "\n",
    "#video = cv2.VideoWriter('/DualStyleGAN/output_C.avi', cv2.VideoWriter_fourcc(*'MJPG'), 10, (320, 320))\n",
    "#for i in range(0,50):\n",
    "#  img = cv2.imread(\"transfer_image_C%d.jpg\"% i)\n",
    "#  img = cv2.resize(img, (320, 320))\n",
    "#  video.write(img)\n",
    "#video.release()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
